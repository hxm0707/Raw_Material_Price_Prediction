{"cells":[{"source":"# Next_month_price_prediction_Alkalis","metadata":{},"cell_type":"markdown","id":"413d7072-e17f-4c75-8250-7346f5c0ef19"},{"source":"## TO-DOs\n```\n[v] Import monthly electrcity data\n[v] Import monthly TTF_GAS data\n[v] Import price evaluatioin data\n[v] Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\n[v] To calculate the monthly average prices of Alkalis\n[v] Create 12*N features, external factor prices from one-month before to 12-month before\n[v] Combine features with target variables\n[] train_test_split() - do calculation and scaling only based on train data set to prevent data leakage\n[x] Detect outliers - skip\n[] Check data distribution\n[] Data scaling\n[] check multicollinearity(to run one regression using each features, and find corr of all feature, filtering those with higher performance and least corr for our last model)\n[] Lasso regression - fit and transform train data set\n[] Lasso regression - transform test data set\n[] Cross validation\n```","metadata":{},"cell_type":"markdown","id":"6b4c7f02-1c48-419e-ae1c-979e205b1891"},{"source":"!pip install fredapi\n!pip install pandasql","metadata":{"executionCancelledAt":null,"executionTime":10953,"lastExecutedAt":1709067117258,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi\n!pip install pandasql","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"e79fdd88-9172-4097-9fa2-b91ab3eef2e5","outputs":[],"execution_count":1},{"source":"import pandas as pd\nfrom fredapi import Fred\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"executionCancelledAt":null,"executionTime":704,"lastExecutedAt":1709067117964,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom fredapi import Fred\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt"},"cell_type":"code","id":"d95bfcf0-14be-44fb-9a51-ceefcff17281","outputs":[],"execution_count":2},{"source":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1709067118016,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"a8ebea83-36e8-4355-b23f-c3b4a33b8602","outputs":[],"execution_count":3},{"source":"## Import monthly electrcity data\nelec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\nelec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\nelec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n\nprint(elec_df.info())\nprint(elec_df.groupby(['Year']).count())\nprint(elec_df.isna().sum().sort_values()) # checking missing values","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"ca1221ea-d302-4c06-a97a-91017aa8eeea","outputs":[],"execution_count":4},{"source":"## Import monthly TTF_GAS data\napiKey = '29219060bc68b2802af8584e0f328b52'\nfred = Fred(api_key=apiKey)\n\n# Get Natural Gas prices in Europe per month\nTTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n                       columns=['PNGASEUUSDM']).reset_index() \nTTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\nTTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\nTTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\nTTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\nTTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n\nprint(TTF_gas_df.info())\nprint(TTF_gas_df.groupby(['Year']).count())\nprint(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n\n\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"b71f7113-0cfa-4a46-8130-9b07e18d20a9","outputs":[],"execution_count":5},{"source":"## Import price evaluatioin data\nprice_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\nprice_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\nprice_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\nprice_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\nprice_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n\nprice_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n\n# Drop unnecessary columns\nprice_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n\nprint(price_evo_df.info())\nprint(price_evo_df.groupby(['Year']).count())\nprint(price_evo_df.isna().sum().sort_values()) # Check missing values\n\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"af06d94f-1218-4363-a83d-f5ac1783022a","outputs":[],"execution_count":6},{"source":"## Create rows and encoding Alkalis_RM02_0001, \n## To calculate the monthly average prices of Alkalis\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\n\n## Calculate the average raw material price\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\nResetting the index of the resulting series is necessary to ensure that the indices align properly when merging the series back into the original dataframe.\n\nWhen you perform a groupby operation in pandas, the resulting object is a new DataFrame or Series with a hierarchical index (MultiIndex) if you group by multiple columns. In your case, when you group by ['Year', 'Month'] and calculate the mean, the resulting Series has a MultiIndex consisting of 'Year' and 'Month'.\n\nMerging this Series directly with the original dataframe without resetting the index could lead to issues because the indices won't align properly, and you may end up with NaN values or incorrect mappings.\n\nResetting the index of the resulting series converts the indices into regular integer indices, making it easier to merge with the original dataframe based on the common columns ('Year' and 'Month'). This ensures that the average prices are correctly aligned with the corresponding rows in the original dataframe.\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\n\n# Merge the average monthly price with the original dataframe\nAlkalis_df_dummies = pd.merge(Alkalis_df_dummies, average_price, on=['Year','Month'], suffixes=('', '_avg'))\n\n# Rename the new column to 'Average_price'\nAlkalis_df_dummies.rename(columns={'PRICE (EUR/kg)_avg': 'Average_price'}, inplace=True)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('PRICE (EUR/kg)', axis=1)\n\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.sort_values('Time'))\nprint(Alkalis_df_dummies.isna().sum().sort_values())\n","metadata":{"executionCancelledAt":null,"executionTime":110,"lastExecutedAt":1709067118535,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create rows and encoding Alkalis_RM02_0001, \n## To calculate the monthly average prices of Alkalis\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\n\n## Calculate the average raw material price\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\nResetting the index of the resulting series is necessary to ensure that the indices align properly when merging the series back into the original dataframe.\n\nWhen you perform a groupby operation in pandas, the resulting object is a new DataFrame or Series with a hierarchical index (MultiIndex) if you group by multiple columns. In your case, when you group by ['Year', 'Month'] and calculate the mean, the resulting Series has a MultiIndex consisting of 'Year' and 'Month'.\n\nMerging this Series directly with the original dataframe without resetting the index could lead to issues because the indices won't align properly, and you may end up with NaN values or incorrect mappings.\n\nResetting the index of the resulting series converts the indices into regular integer indices, making it easier to merge with the original dataframe based on the common columns ('Year' and 'Month'). This ensures that the average prices are correctly aligned with the corresponding rows in the original dataframe.\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\n\n# Merge the average monthly price with the original dataframe\nAlkalis_df_dummies = pd.merge(Alkalis_df_dummies, average_price, on=['Year','Month'], suffixes=('', '_avg'))\n\n# Rename the new column to 'Average_price'\nAlkalis_df_dummies.rename(columns={'PRICE (EUR/kg)_avg': 'Average_price'}, inplace=True)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('PRICE (EUR/kg)', axis=1)\n\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.sort_values('Time'))\nprint(Alkalis_df_dummies.isna().sum().sort_values())\n","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"dcfaf48e-a15e-463f-9616-1a05c2f13f3e","outputs":[],"execution_count":7},{"source":"## Create 12*N features, external factor prices from one-month before to 12-month before\n## Combine features with target variables\n# To prepare feature datasets\nmerged_df = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\nfeature_df = merged_df.copy()\nfeature_df['Time_label'] = feature_df['Time'].dt.strftime('%Y-%m')\nfeature_df = feature_df.drop(['Year','Month', 'Time'], axis=1) # to prevent duplicate columns when merging\n\n# create time labels\nlabel_dfs=[]    # To store labels\n                # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\n    \nfor i in range(1,13): # 13 is not included\n    label = Alkalis_df_dummies[['Time']]\n    label.rename(columns = {'Time':f'Time_label{i}'}, inplace = True)\n    label = (label[f'Time_label{i}'] - pd.DateOffset(months=i)).dt.strftime('%Y-%m')\n    label_dfs.append(label)\n\nresult = pd.concat(label_dfs, axis=1)\n\n# To merge with features\nfor i in range(1,13): # 13 is not included\n    result = result.merge(feature_df, how='left',\\\n                          left_on=[f'Time_label{i}'],\\\n                          right_on=['Time_label'])\n    result.rename(columns = {'Electricity':f'Electricity_{i}',\n                              'PNGASEUUSDM':f'PNGASEUUSDM_{i}'\n                             }, inplace = True)\n    result = result.drop(['Time_label',f'Time_label{i}'], axis=1)\n    \nAlkalis_df_dummies = pd.concat([Alkalis_df_dummies,result],axis=1)\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies)\n","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":431,"type":"stream"}}},"cell_type":"code","id":"af348660-2ae0-4781-bd13-8649ecd482d1","outputs":[],"execution_count":8}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}