{"cells":[{"cell_type":"markdown","id":"413d7072-e17f-4c75-8250-7346f5c0ef19","metadata":{},"source":["# Next_month_price_prediction_Alkalis"]},{"cell_type":"markdown","id":"6b4c7f02-1c48-419e-ae1c-979e205b1891","metadata":{},"source":["## TO-DOs\n","```\n","[v] Import monthly electrcity data\n","[v] Import monthly TTF_GAS data\n","[v] Import price evaluatioin data\n","[v] Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\n","[v] Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n","[v] To create a column indicating how many monthes was shifted, 'Monthes_shifted'\n","[v] To create dummy variables for 'Monthes_shifted'\n","[] Combine features with target variables\n","[] train_test_split() - do calculation and scaling only based on train data set to prevent data leakage\n","[] Detect outliers\n","[] Check data distribution\n","[] Data scaling\n","[] check multicollinearity(to run one regression using each features, and find corr of all feature, filtering those with higher performance and least corr for our last model)\n","[] Lasso regression - fit and transform train data set\n","[] Lasso regression - transform test data set\n","[] Cross validation\n","```"]},{"cell_type":"code","execution_count":9,"id":"e79fdd88-9172-4097-9fa2-b91ab3eef2e5","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":10371,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1708962645745,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi\n!pip install pandasql","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: fredapi in /home/repl/.local/lib/python3.8/site-packages (0.5.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fredapi) (1.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (2022.7)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (1.23.2)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->fredapi) (1.14.0)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: pandasql in /usr/local/lib/python3.8/dist-packages (0.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.23.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.5.1)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.4.40)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2022.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy->pandasql) (1.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.14.0)\n"]}],"source":["!pip install fredapi\n","!pip install pandasql"]},{"cell_type":"code","execution_count":10,"id":"d95bfcf0-14be-44fb-9a51-ceefcff17281","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708962645797,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom fredapi import Fred\nfrom pandasql import sqldf\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt"},"outputs":[],"source":["import pandas as pd\n","from fredapi import Fred\n","from pandasql import sqldf\n","from sklearn.linear_model import Lasso\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":11,"id":"a8ebea83-36e8-4355-b23f-c3b4a33b8602","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":51,"jupyter":{"outputs_hidden":false,"source_hidden":true},"lastExecutedAt":1708962645849,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily"},"outputs":[],"source":["def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n","    \"\"\"\n","    Convert Monthly data into Daily data and impute with monthly mean prices\n","    \"\"\"\n","    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n","    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n","\n","    # Generate a complete range of daily dates for the year for imputation\n","    start_date = df['Date'].min() # represents the starting point of your data\n","    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n","    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n","\n","    # Merge the full date range with the monthly averages to fill in all days\n","    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n","    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n","    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n","    return df_daily"]},{"cell_type":"code","execution_count":12,"id":"ca1221ea-d302-4c06-a97a-91017aa8eeea","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":52,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1708962645902,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly electrcity data\nelec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\nelec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\nelec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n\nprint(elec_df.info())\nprint(elec_df.groupby(['Year']).count())\nprint(elec_df.isna().sum().sort_values()) # checking missing values","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 156 entries, 0 to 155\n","Data columns (total 4 columns):\n"," #   Column       Non-Null Count  Dtype         \n","---  ------       --------------  -----         \n"," 0   Year         156 non-null    int64         \n"," 1   Month        156 non-null    int64         \n"," 2   Electricity  156 non-null    float64       \n"," 3   Time         156 non-null    datetime64[ns]\n","dtypes: datetime64[ns](1), float64(1), int64(2)\n","memory usage: 5.0 KB\n","None\n","      Month  Electricity  Time\n","Year                          \n","2011     12           12    12\n","2012     12           12    12\n","2013     12           12    12\n","2014     12           12    12\n","2015     12           12    12\n","2016     12           12    12\n","2017     12           12    12\n","2018     12           12    12\n","2019     12           12    12\n","2020     12           12    12\n","2021     12           12    12\n","2022     12           12    12\n","2023     12           12    12\n","Year           0\n","Month          0\n","Electricity    0\n","Time           0\n","dtype: int64\n"]}],"source":["## Import monthly electrcity data\n","elec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\n","elec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\n","elec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n","\n","print(elec_df.info())\n","print(elec_df.groupby(['Year']).count())\n","print(elec_df.isna().sum().sort_values()) # checking missing values"]},{"cell_type":"code","execution_count":13,"id":"b71f7113-0cfa-4a46-8130-9b07e18d20a9","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":198,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1708962646100,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly TTF_GAS data\napiKey = '29219060bc68b2802af8584e0f328b52'\nfred = Fred(api_key=apiKey)\n\n# Get Natural Gas prices in Europe per month\nTTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n                       columns=['PNGASEUUSDM']).reset_index() \nTTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\nTTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\nTTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\nTTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\nTTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n\nprint(TTF_gas_df.info())\nprint(TTF_gas_df.groupby(['Year']).count())\nprint(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n\n\n","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 156 entries, 312 to 467\n","Data columns (total 4 columns):\n"," #   Column       Non-Null Count  Dtype         \n","---  ------       --------------  -----         \n"," 0   Time         156 non-null    datetime64[ns]\n"," 1   PNGASEUUSDM  156 non-null    float64       \n"," 2   Year         156 non-null    int64         \n"," 3   Month        156 non-null    int64         \n","dtypes: datetime64[ns](1), float64(1), int64(2)\n","memory usage: 6.1 KB\n","None\n","      Time  PNGASEUUSDM  Month\n","Year                          \n","2011    12           12     12\n","2012    12           12     12\n","2013    12           12     12\n","2014    12           12     12\n","2015    12           12     12\n","2016    12           12     12\n","2017    12           12     12\n","2018    12           12     12\n","2019    12           12     12\n","2020    12           12     12\n","2021    12           12     12\n","2022    12           12     12\n","2023    12           12     12\n","Time           0\n","PNGASEUUSDM    0\n","Year           0\n","Month          0\n","dtype: int64\n"]}],"source":["## Import monthly TTF_GAS data\n","apiKey = '29219060bc68b2802af8584e0f328b52'\n","fred = Fred(api_key=apiKey)\n","\n","# Get Natural Gas prices in Europe per month\n","TTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n","                       columns=['PNGASEUUSDM']).reset_index() \n","TTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\n","TTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\n","TTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\n","TTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\n","TTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n","\n","print(TTF_gas_df.info())\n","print(TTF_gas_df.groupby(['Year']).count())\n","print(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n","\n","\n"]},{"cell_type":"code","execution_count":14,"id":"af06d94f-1218-4363-a83d-f5ac1783022a","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":74,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1708962646174,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import price evaluatioin data\nprice_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\nprice_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\nprice_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\nprice_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\nprice_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n\nprice_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n\n# Drop unnecessary columns\nprice_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n\nprint(price_evo_df.info())\nprint(price_evo_df.groupby(['Year']).count())\nprint(price_evo_df.isna().sum().sort_values()) # Check missing values\n\n","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20570 entries, 0 to 20569\n","Data columns (total 6 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   Time               20570 non-null  datetime64[ns]\n"," 1   Group Description  20570 non-null  object        \n"," 2   Key RM code        20570 non-null  object        \n"," 3   PRICE (EUR/kg)     20570 non-null  float64       \n"," 4   Year               20570 non-null  int64         \n"," 5   Month              20570 non-null  int64         \n","dtypes: datetime64[ns](1), float64(1), int64(2), object(2)\n","memory usage: 964.3+ KB\n","None\n","      Time  Group Description  Key RM code  PRICE (EUR/kg)  Month\n","Year                                                             \n","2012   604                604          604             604    604\n","2013   634                634          634             634    634\n","2014   803                803          803             803    803\n","2015   860                860          860             860    860\n","2016  1057               1057         1057            1057   1057\n","2017  1339               1339         1339            1339   1339\n","2018  1589               1589         1589            1589   1589\n","2019  2151               2151         2151            2151   2151\n","2020  2403               2403         2403            2403   2403\n","2021  2954               2954         2954            2954   2954\n","2022  3215               3215         3215            3215   3215\n","2023  2961               2961         2961            2961   2961\n","Time                 0\n","Group Description    0\n","Key RM code          0\n","PRICE (EUR/kg)       0\n","Year                 0\n","Month                0\n","dtype: int64\n"]}],"source":["## Import price evaluatioin data\n","price_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\n","price_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\n","price_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\n","price_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n","# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\n","price_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n","\n","price_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n","\n","# Drop unnecessary columns\n","price_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n","\n","print(price_evo_df.info())\n","print(price_evo_df.groupby(['Year']).count())\n","print(price_evo_df.isna().sum().sort_values()) # Check missing values\n","\n"]},{"cell_type":"code","execution_count":17,"id":"dcfaf48e-a15e-463f-9616-1a05c2f13f3e","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":32,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1708963610846,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.sort_values('Time').head(20))","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 6007 entries, 0 to 6006\n","Data columns (total 6 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   Time               6007 non-null   datetime64[ns]\n"," 1   Group Description  6007 non-null   object        \n"," 2   PRICE (EUR/kg)     6007 non-null   float64       \n"," 3   Year               6007 non-null   int64         \n"," 4   Month              6007 non-null   int64         \n"," 5   RM02/0002          6007 non-null   uint8         \n","dtypes: datetime64[ns](1), float64(1), int64(2), object(1), uint8(1)\n","memory usage: 240.6+ KB\n","None\n","         Time Group Description  PRICE (EUR/kg)  Year  Month  RM02/0002\n","0  2012-01-31           Alkalis           0.215  2012      1          0\n","1  2012-01-31           Alkalis           0.215  2012      1          0\n","2  2012-01-31           Alkalis           0.217  2012      1          0\n","3  2012-01-31           Alkalis           0.215  2012      1          0\n","4  2012-01-31           Alkalis           0.205  2012      1          0\n","5  2012-01-31           Alkalis           0.217  2012      1          0\n","6  2012-01-31           Alkalis           0.215  2012      1          0\n","7  2012-01-31           Alkalis           0.215  2012      1          0\n","16 2012-02-24           Alkalis           0.410  2012      2          1\n","15 2012-02-29           Alkalis           0.215  2012      2          0\n","13 2012-02-29           Alkalis           0.215  2012      2          0\n","12 2012-02-29           Alkalis           0.217  2012      2          0\n","14 2012-02-29           Alkalis           0.217  2012      2          0\n","10 2012-02-29           Alkalis           0.215  2012      2          0\n","9  2012-02-29           Alkalis           0.215  2012      2          0\n","8  2012-02-29           Alkalis           0.217  2012      2          0\n","11 2012-02-29           Alkalis           0.217  2012      2          0\n","36 2012-03-02           Alkalis           0.217  2012      3          0\n","35 2012-03-02           Alkalis           0.215  2012      3          0\n","34 2012-03-02           Alkalis           0.215  2012      3          0\n"]}],"source":["## Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\n","Alkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\n","Alkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n","\n","# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\n","Alkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n","\n","# combine dummy variables with Alkalis_df\n","Alkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\n","Alkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\n","print(Alkalis_df_dummies.info())\n","print(Alkalis_df_dummies.sort_values('Time').head(20))"]},{"cell_type":"code","execution_count":36,"id":"2ae5fc25-16d2-4085-ac3d-e48ce3db8a59","metadata":{"executionCancelledAt":null,"executionTime":65,"lastExecutedAt":1708966198701,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n# To merge TTF_gas and Electricity prices\ndf_merged = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\n\n# To create a historical prices vary from 1 month to 12 mothes ago, and combine them into one table indicating shifted durations by 'Shifted_Monthes'\nshifts = np.linspace(1,12,12)\nhistorical_dfs = [] # To store shifted dfs\n                    # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\nfor i in shifts:\n    df = df_merged.copy() # Make a copy to avoid modifying the original dataframe\n    mask = df['Time'] - pd.DateOffset(months=i) # pd.DateOffset performs date arithmetic.\n    df_shifted = df[df['Time'].isin(mask)]\n\n    # To join historical prices based on 'Shifted_time', changing type() from datetime to string to align the values\n    df_shifted['Time'] = df_shifted['Time'].dt.strftime('%Y-%m')\n    df_shifted.rename(columns = {'Time':'Shifted_time',\n                                'Electricity':'His_Electricity',\n                                'PNGASEUUSDM':'His_PNGASEUUSDM'}, inplace = True)\n    # To prevent duplicate columns with Alkalis_df_dummies\n    df_shifted = df_shifted.drop(['Year', 'Month'], axis=1)\n    \n    # To indicate this row includes the data i monthes ago\n    df_shifted['Shifted_Monthes'] = int(i) \n    \n    historical_dfs.append(df_shifted)\n\n    \ndf_shifted_combined = pd.concat(historical_dfs, ignore_index=True)\n\n\n\n\n# encoding historical feature prices by 'Shifted_Monthes' with n-1 dummy variables\ndummies = pd.get_dummies(df_shifted_combined['Shifted_Monthes'], drop_first=True)\\\n            .add_suffix('_monthes_ago')\n\n# combine dummy variables with df_shifted_combined\ndf_shifted_combined = pd.concat([df_shifted_combined, dummies], axis=1)\ndf_shifted_combined = df_shifted_combined.drop('Shifted_Monthes', axis=1)\n\nprint(df_shifted_combined.info())\nprint(df_shifted_combined.head())\n\n\n    \n\n\n\n# To-Dos, to merge combined dfs into Alkalis_df_dummies\n#     test = Alkalis_df_dummies.copy()\n#     test['Shifted_time'] = (test['Time'] - pd.DateOffset(months=i))\\\n#                                         .dt.strftime('%Y-%m')\n# result = pd.merge(df_shifted, df_shifted,how='left', on = (['Shifted_time']))\n# print(result)","outputsMetadata":{"0":{"height":377,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1794 entries, 0 to 1793\n","Data columns (total 14 columns):\n"," #   Column           Non-Null Count  Dtype  \n","---  ------           --------------  -----  \n"," 0   His_Electricity  1794 non-null   float64\n"," 1   Shifted_time     1794 non-null   object \n"," 2   His_PNGASEUUSDM  1794 non-null   float64\n"," 3   2_monthes_ago    1794 non-null   uint8  \n"," 4   3_monthes_ago    1794 non-null   uint8  \n"," 5   4_monthes_ago    1794 non-null   uint8  \n"," 6   5_monthes_ago    1794 non-null   uint8  \n"," 7   6_monthes_ago    1794 non-null   uint8  \n"," 8   7_monthes_ago    1794 non-null   uint8  \n"," 9   8_monthes_ago    1794 non-null   uint8  \n"," 10  9_monthes_ago    1794 non-null   uint8  \n"," 11  10_monthes_ago   1794 non-null   uint8  \n"," 12  11_monthes_ago   1794 non-null   uint8  \n"," 13  12_monthes_ago   1794 non-null   uint8  \n","dtypes: float64(2), object(1), uint8(11)\n","memory usage: 61.4+ KB\n","None\n","   His_Electricity Shifted_time  ...  11_monthes_ago  12_monthes_ago\n","0            56.66      2011-01  ...               0               0\n","1            56.13      2012-01  ...               0               0\n","2            62.04      2013-01  ...               0               0\n","3            56.01      2014-01  ...               0               0\n","4            56.88      2015-01  ...               0               0\n","\n","[5 rows x 14 columns]\n"]}],"source":["## Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n","# To merge TTF_gas and Electricity prices\n","df_merged = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\n","\n","# To create a historical prices vary from 1 month to 12 mothes ago, and combine them into one table indicating shifted durations by 'Shifted_Monthes'\n","shifts = np.linspace(1,12,12)\n","historical_dfs = [] # To store shifted dfs\n","                    # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\n","for i in shifts:\n","    df = df_merged.copy() # Make a copy to avoid modifying the original dataframe\n","    mask = df['Time'] - pd.DateOffset(months=i) # pd.DateOffset performs date arithmetic.\n","    df_shifted = df[df['Time'].isin(mask)]\n","\n","    # To join historical prices based on 'Shifted_time', changing type() from datetime to string to align the values\n","    df_shifted['Time'] = df_shifted['Time'].dt.strftime('%Y-%m')\n","    df_shifted.rename(columns = {'Time':'Shifted_time',\n","                                'Electricity':'His_Electricity',\n","                                'PNGASEUUSDM':'His_PNGASEUUSDM'}, inplace = True)\n","    # To prevent duplicate columns with Alkalis_df_dummies\n","    df_shifted = df_shifted.drop(['Year', 'Month'], axis=1)\n","    \n","    # To indicate this row includes the data i monthes ago\n","    df_shifted['Shifted_Monthes'] = int(i) \n","    \n","    historical_dfs.append(df_shifted)\n","\n","    \n","df_shifted_combined = pd.concat(historical_dfs, ignore_index=True)\n","\n","\n","\n","\n","# encoding historical feature prices by 'Shifted_Monthes' with n-1 dummy variables\n","dummies = pd.get_dummies(df_shifted_combined['Shifted_Monthes'], drop_first=True)\\\n","            .add_suffix('_monthes_ago')\n","\n","# combine dummy variables with df_shifted_combined\n","df_shifted_combined = pd.concat([df_shifted_combined, dummies], axis=1)\n","df_shifted_combined = df_shifted_combined.drop('Shifted_Monthes', axis=1)\n","\n","print(df_shifted_combined.info())\n","print(df_shifted_combined.head())\n","\n","# To-Dos, to merge combined dfs into Alkalis_df_dummies\n","#     test = Alkalis_df_dummies.copy()\n","#     test['Shifted_time'] = (test['Time'] - pd.DateOffset(months=i))\\\n","#                                         .dt.strftime('%Y-%m')\n","# result = pd.merge(df_shifted, df_shifted,how='left', on = (['Shifted_time']))\n","# print(result)"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
