{"cells":[{"source":"# Next_month_price_prediction_Alkalis","metadata":{},"cell_type":"markdown","id":"413d7072-e17f-4c75-8250-7346f5c0ef19"},{"source":"## TO-DOs\n```\n[v] Import monthly electrcity data\n[v] Import monthly TTF_GAS data\n[v] Import price evaluatioin data\n[v] Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\n[] Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n[] To create a column indicating how many monthes was shifted, 'Monthes_shifted'\n[] To create dummy variables for 'Monthes_shifted'\n[] Combine features with target variables\n[] train_test_split() - do calculation and scaling only based on train data set to prevent data leakage\n[] Detect outliers\n[] Check data distribution\n[] Data scaling\n[] check multicollinearity(to run one regression using each features, and find corr of all feature, filtering those with higher performance and least corr for our last model)\n[] Lasso regression - fit and transform train data set\n[] Lasso regression - transform test data set\n[] Cross validation\n```","metadata":{},"cell_type":"markdown","id":"6b4c7f02-1c48-419e-ae1c-979e205b1891"},{"source":"!pip install fredapi\n!pip install pandasql","metadata":{"executionCancelledAt":null,"executionTime":10547,"lastExecutedAt":1708896936150,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi\n!pip install pandasql","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"e79fdd88-9172-4097-9fa2-b91ab3eef2e5","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: fredapi in /home/repl/.local/lib/python3.8/site-packages (0.5.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from fredapi) (1.5.1)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (2022.7)\nRequirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.8/dist-packages (from pandas->fredapi) (1.23.2)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->fredapi) (1.14.0)\nDefaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: pandasql in /usr/local/lib/python3.8/dist-packages (0.7.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.23.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.5.1)\nRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.4.40)\nRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2022.7)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy->pandasql) (1.1.3)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.14.0)\n"}],"execution_count":75},{"source":"import pandas as pd\nfrom fredapi import Fred\nfrom pandasql import sqldf\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708896936202,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom fredapi import Fred\nfrom pandasql import sqldf\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt"},"cell_type":"code","id":"d95bfcf0-14be-44fb-9a51-ceefcff17281","outputs":[],"execution_count":76},{"source":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1708896936254,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily","collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":true}},"cell_type":"code","id":"a8ebea83-36e8-4355-b23f-c3b4a33b8602","outputs":[],"execution_count":77},{"source":"## Import monthly electrcity data\nelec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\nelec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\nelec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n\nprint(elec_df.info())\nprint(elec_df.groupby(['Year']).count())\nprint(elec_df.isna().sum().sort_values()) # checking missing values","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1708896936307,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly electrcity data\nelec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\nelec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\nelec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n\nprint(elec_df.info())\nprint(elec_df.groupby(['Year']).count())\nprint(elec_df.isna().sum().sort_values()) # checking missing values","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"ca1221ea-d302-4c06-a97a-91017aa8eeea","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 156 entries, 0 to 155\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype         \n---  ------       --------------  -----         \n 0   Year         156 non-null    int64         \n 1   Month        156 non-null    int64         \n 2   Electricity  156 non-null    float64       \n 3   Time         156 non-null    datetime64[ns]\ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 5.0 KB\nNone\n      Month  Electricity  Time\nYear                          \n2011     12           12    12\n2012     12           12    12\n2013     12           12    12\n2014     12           12    12\n2015     12           12    12\n2016     12           12    12\n2017     12           12    12\n2018     12           12    12\n2019     12           12    12\n2020     12           12    12\n2021     12           12    12\n2022     12           12    12\n2023     12           12    12\nYear           0\nMonth          0\nElectricity    0\nTime           0\ndtype: int64\n"}],"execution_count":78},{"source":"## Import monthly TTF_GAS data\napiKey = '29219060bc68b2802af8584e0f328b52'\nfred = Fred(api_key=apiKey)\n\n# Get Natural Gas prices in Europe per month\nTTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n                       columns=['PNGASEUUSDM']).reset_index() \nTTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\nTTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\nTTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\nTTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\nTTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n\nprint(TTF_gas_df.info())\nprint(TTF_gas_df.groupby(['Year']).count())\nprint(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n\n\n","metadata":{"executionCancelledAt":null,"executionTime":190,"lastExecutedAt":1708896936497,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly TTF_GAS data\napiKey = '29219060bc68b2802af8584e0f328b52'\nfred = Fred(api_key=apiKey)\n\n# Get Natural Gas prices in Europe per month\nTTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n                       columns=['PNGASEUUSDM']).reset_index() \nTTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\nTTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\nTTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\nTTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\nTTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n\nprint(TTF_gas_df.info())\nprint(TTF_gas_df.groupby(['Year']).count())\nprint(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n\n\n","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"b71f7113-0cfa-4a46-8130-9b07e18d20a9","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 156 entries, 312 to 467\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype         \n---  ------       --------------  -----         \n 0   Time         156 non-null    datetime64[ns]\n 1   PNGASEUUSDM  156 non-null    float64       \n 2   Year         156 non-null    int64         \n 3   Month        156 non-null    int64         \ndtypes: datetime64[ns](1), float64(1), int64(2)\nmemory usage: 6.1 KB\nNone\n      Time  PNGASEUUSDM  Month\nYear                          \n2011    12           12     12\n2012    12           12     12\n2013    12           12     12\n2014    12           12     12\n2015    12           12     12\n2016    12           12     12\n2017    12           12     12\n2018    12           12     12\n2019    12           12     12\n2020    12           12     12\n2021    12           12     12\n2022    12           12     12\n2023    12           12     12\nTime           0\nPNGASEUUSDM    0\nYear           0\nMonth          0\ndtype: int64\n"}],"execution_count":79},{"source":"## Import price evaluatioin data\nprice_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\nprice_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\nprice_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\nprice_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\nprice_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n\nprice_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n\n# Drop unnecessary columns\nprice_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n\nprint(price_evo_df.info())\nprint(price_evo_df.groupby(['Year']).count())\nprint(price_evo_df.isna().sum().sort_values()) # Check missing values\n\n","metadata":{"executionCancelledAt":null,"executionTime":78,"lastExecutedAt":1708896936575,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import price evaluatioin data\nprice_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\nprice_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\nprice_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\nprice_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\nprice_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n\nprice_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n\n# Drop unnecessary columns\nprice_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n\nprint(price_evo_df.info())\nprint(price_evo_df.groupby(['Year']).count())\nprint(price_evo_df.isna().sum().sort_values()) # Check missing values\n\n","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"af06d94f-1218-4363-a83d-f5ac1783022a","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 20570 entries, 0 to 20569\nData columns (total 6 columns):\n #   Column             Non-Null Count  Dtype         \n---  ------             --------------  -----         \n 0   Time               20570 non-null  datetime64[ns]\n 1   Group Description  20570 non-null  object        \n 2   Key RM code        20570 non-null  object        \n 3   PRICE (EUR/kg)     20570 non-null  float64       \n 4   Year               20570 non-null  int64         \n 5   Month              20570 non-null  int64         \ndtypes: datetime64[ns](1), float64(1), int64(2), object(2)\nmemory usage: 964.3+ KB\nNone\n      Time  Group Description  Key RM code  PRICE (EUR/kg)  Month\nYear                                                             \n2012   604                604          604             604    604\n2013   634                634          634             634    634\n2014   803                803          803             803    803\n2015   860                860          860             860    860\n2016  1057               1057         1057            1057   1057\n2017  1339               1339         1339            1339   1339\n2018  1589               1589         1589            1589   1589\n2019  2151               2151         2151            2151   2151\n2020  2403               2403         2403            2403   2403\n2021  2954               2954         2954            2954   2954\n2022  3215               3215         3215            3215   3215\n2023  2961               2961         2961            2961   2961\nTime                 0\nGroup Description    0\nKey RM code          0\nPRICE (EUR/kg)       0\nYear                 0\nMonth                0\ndtype: int64\n"}],"execution_count":80},{"source":"## Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.groupby(['Year']).count())\nprint(Alkalis_df_dummies.sort_values('Time').head(20))","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1708896936627,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.groupby(['Year']).count())\nprint(Alkalis_df_dummies.sort_values('Time').head(20))","outputsMetadata":{"0":{"height":431,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"dcfaf48e-a15e-463f-9616-1a05c2f13f3e","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 6007 entries, 0 to 6006\nData columns (total 6 columns):\n #   Column             Non-Null Count  Dtype         \n---  ------             --------------  -----         \n 0   Time               6007 non-null   datetime64[ns]\n 1   Group Description  6007 non-null   object        \n 2   PRICE (EUR/kg)     6007 non-null   float64       \n 3   Year               6007 non-null   int64         \n 4   Month              6007 non-null   int64         \n 5   RM02/0002          6007 non-null   uint8         \ndtypes: datetime64[ns](1), float64(1), int64(2), object(1), uint8(1)\nmemory usage: 240.6+ KB\nNone\n      Time  Group Description  PRICE (EUR/kg)  Month  RM02/0002\nYear                                                           \n2012   148                148             148    148        148\n2013   182                182             182    182        182\n2014   219                219             219    219        219\n2015   231                231             231    231        231\n2016   263                263             263    263        263\n2017   326                326             326    326        326\n2018   427                427             427    427        427\n2019   719                719             719    719        719\n2020   728                728             728    728        728\n2021   877                877             877    877        877\n2022  1012               1012            1012   1012       1012\n2023   875                875             875    875        875\n         Time Group Description  PRICE (EUR/kg)  Year  Month  RM02/0002\n0  2012-01-31           Alkalis           0.215  2012      1          0\n1  2012-01-31           Alkalis           0.215  2012      1          0\n2  2012-01-31           Alkalis           0.217  2012      1          0\n3  2012-01-31           Alkalis           0.215  2012      1          0\n4  2012-01-31           Alkalis           0.205  2012      1          0\n5  2012-01-31           Alkalis           0.217  2012      1          0\n6  2012-01-31           Alkalis           0.215  2012      1          0\n7  2012-01-31           Alkalis           0.215  2012      1          0\n16 2012-02-24           Alkalis           0.410  2012      2          1\n15 2012-02-29           Alkalis           0.215  2012      2          0\n13 2012-02-29           Alkalis           0.215  2012      2          0\n12 2012-02-29           Alkalis           0.217  2012      2          0\n14 2012-02-29           Alkalis           0.217  2012      2          0\n10 2012-02-29           Alkalis           0.215  2012      2          0\n9  2012-02-29           Alkalis           0.215  2012      2          0\n8  2012-02-29           Alkalis           0.217  2012      2          0\n11 2012-02-29           Alkalis           0.217  2012      2          0\n36 2012-03-02           Alkalis           0.217  2012      3          0\n35 2012-03-02           Alkalis           0.215  2012      3          0\n34 2012-03-02           Alkalis           0.215  2012      3          0\n"}],"execution_count":81},{"source":"## Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n# To merge TTF_gas and Electricity prices\ndf_merged = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\n\n# To create a historical prices vary from 1 month to 12 mothes ago, and combine them into one table indicating shifted durations by 'Shifted_Monthes'\nshifts = np.linspace(1,12,12)\nhistorical_dfs = [] # To store shifted dfs\n                    # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\nfor i in shifts:\n    df = df_merged.copy() # Make a copy to avoid modifying the original dataframe\n    mask = df['Time'] - pd.DateOffset(months=i) # pd.DateOffset performs date arithmetic.\n    df_shifted = df[df['Time'].isin(mask)]\n\n    # To join historical prices based on 'Shifted_time', changing type() from datetime to string to align the values\n    df_shifted['Time'] = df_shifted['Time'].dt.strftime('%Y-%m')\n    df_shifted.rename(columns = {'Time':'Shifted_time',\n                                'Electricity':'His_Electricity',\n                                'PNGASEUUSDM':'His_PNGASEUUSDM'}, inplace = True)\n    # To prevent duplicate columns with Alkalis_df_dummies\n    df_shifted = df_shifted.drop(['Year', 'Month'], axis=1)\n    \n    # To indicate this row includes the data i monthes ago\n    df_shifted['Shifted_Monthes'] = int(i) \n    \n    historical_dfs.append(df_shifted)\n    df_shifted_combined = pd.concat(historical_dfs, ignore_index=True)\n\nprint(df_shifted_combined.info())\n    # Alkalis_df_dummies['Shifted_time'] = (Alkalis_df_dummies['Time'] - pd.DateOffset(months=i)).dt.strftime('%Y-%m')\n    \n# result = pd.merge(df_shifted, df_shifted,how='left', on = (['Shifted_time']))\n\n\n# To-Dos, to merge combined dfs into Alkalis_df_dummies\n# To create dummy variables for 'Shifted_Monthes'","metadata":{"executionCancelledAt":null,"executionTime":61,"lastExecutedAt":1708897589056,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create 12 features, external factor prices from one-month before to 12-month before, and encoding datetime data\n# To merge TTF_gas and Electricity prices\ndf_merged = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\n\n# To create a historical prices vary from 1 month to 12 mothes ago, and combine them into one table indicating shifted durations by 'Shifted_Monthes'\nshifts = np.linspace(1,12,12)\nhistorical_dfs = [] # To store shifted dfs\n                    # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\nfor i in shifts:\n    df = df_merged.copy() # Make a copy to avoid modifying the original dataframe\n    mask = df['Time'] - pd.DateOffset(months=i) # pd.DateOffset performs date arithmetic.\n    df_shifted = df[df['Time'].isin(mask)]\n\n    # To join historical prices based on 'Shifted_time', changing type() from datetime to string to align the values\n    df_shifted['Time'] = df_shifted['Time'].dt.strftime('%Y-%m')\n    df_shifted.rename(columns = {'Time':'Shifted_time',\n                                'Electricity':'His_Electricity',\n                                'PNGASEUUSDM':'His_PNGASEUUSDM'}, inplace = True)\n    # To prevent duplicate columns with Alkalis_df_dummies\n    df_shifted = df_shifted.drop(['Year', 'Month'], axis=1)\n    \n    # To indicate this row includes the data i monthes ago\n    df_shifted['Shifted_Monthes'] = int(i) \n    \n    historical_dfs.append(df_shifted)\n    df_shifted_combined = pd.concat(historical_dfs, ignore_index=True)\n\nprint(df_shifted_combined.info())\n    # Alkalis_df_dummies['Shifted_time'] = (Alkalis_df_dummies['Time'] - pd.DateOffset(months=i)).dt.strftime('%Y-%m')\n    \n# result = pd.merge(df_shifted, df_shifted,how='left', on = (['Shifted_time']))\n\n\n# To-Dos, to merge combined dfs into Alkalis_df_dummies\n# To create dummy variables for 'Shifted_Monthes'","outputsMetadata":{"0":{"height":257,"type":"stream"}}},"cell_type":"code","id":"2ae5fc25-16d2-4085-ac3d-e48ce3db8a59","outputs":[{"output_type":"stream","name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1794 entries, 0 to 1793\nData columns (total 4 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   His_Electricity  1794 non-null   float64\n 1   Shifted_time     1794 non-null   object \n 2   His_PNGASEUUSDM  1794 non-null   float64\n 3   Shifted_Monthes  1794 non-null   int64  \ndtypes: float64(2), int64(1), object(1)\nmemory usage: 56.2+ KB\nNone\n"}],"execution_count":92}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}