{"cells":[{"cell_type":"markdown","id":"413d7072-e17f-4c75-8250-7346f5c0ef19","metadata":{},"source":["# One_month_prediction_Alkalis"]},{"cell_type":"markdown","id":"6b4c7f02-1c48-419e-ae1c-979e205b1891","metadata":{},"source":["## TO-DOs\n","```\n","[v] Import monthly electrcity data\n","[v] Import monthly TTF_GAS data\n","[v] Import price evaluatioin data\n","[v] Create rows and encoding Alkalis_RM02_0001, Alkalis_RM02_0002\n","[v] To calculate the monthly average prices of Alkalis\n","[v] Create 12*N features, external factor prices from one-month before to 12-month before\n","[v] Combine features with target variables\n","[v] train_test_split() - do calculation and scaling only based on train data set to prevent data leakage\n","[x] Detect outliers - skip\n","[v] Check data distribution\n","[v] Data scaling - log transformation\n","[] check multicollinearity(to run one regression using each features, and find corr of all feature, filtering those with higher performance and least corr for our last model)\n","[v] Lasso regression - fit and transform train data set\n","[] Cross validation and Hyperparameter tuning using RandomizedSearchCV\n","[] Lasso regression - transform test data set\n","```"]},{"cell_type":"code","execution_count":13,"id":"e79fdd88-9172-4097-9fa2-b91ab3eef2e5","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":5933,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1709499694047,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi\n!pip install pandasql","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["^C\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip\", line 5, in <module>\n","    from pip._internal.cli.main import main\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n","    from pip._internal.cli.autocompletion import autocomplete\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n","    from pip._internal.cli.main_parser import create_main_parser\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n","    from pip._internal.build_env import get_runnable_pip\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n","    from pip._internal.cli.spinners import open_spinner\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n","    from pip._internal.utils.logging import get_indentation\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n","    from pip._vendor.rich.console import (\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 47, in <module>\n","    from . import errors, themes\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/themes.py\", line 1, in <module>\n","    from .default_styles import DEFAULT_STYLES\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/default_styles.py\", line 3, in <module>\n","    from .style import Style\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/style.py\", line 8, in <module>\n","    from .color import Color, ColorParseError, ColorSystem, blend_rgb\n","  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/color.py\", line 10, in <module>\n","    from .repr import Result, rich_repr\n","  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 657, in _load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 562, in module_from_spec\n","  File \"<frozen importlib._bootstrap>\", line 541, in _init_module_attrs\n","  File \"<frozen importlib._bootstrap>\", line 382, in cached\n","  File \"<frozen importlib._bootstrap_external>\", line 487, in _get_cached\n","  File \"<frozen importlib._bootstrap_external>\", line 396, in cache_from_source\n","KeyboardInterrupt\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: pandasql in /usr/local/lib/python3.8/dist-packages (0.7.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.23.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.5.1)\n","Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.8/dist-packages (from pandasql) (1.4.40)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->pandasql) (2022.7)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy->pandasql) (1.1.3)\n","Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.14.0)\n"]}],"source":["!pip install fredapi\n","!pip install pandasql"]},{"cell_type":"code","execution_count":14,"id":"d95bfcf0-14be-44fb-9a51-ceefcff17281","metadata":{"executionCancelledAt":null,"executionTime":46,"lastExecutedAt":1709499694095,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import pandas as pd\nfrom fredapi import Fred\nfrom sklearn.linear_model import Lasso\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.model_selection import RandomizedSearchCV\nimport numpy as np\nimport matplotlib.pyplot as plt"},"outputs":[],"source":["import pandas as pd\n","from fredapi import Fred\n","from sklearn.linear_model import Lasso\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.model_selection import RandomizedSearchCV\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":15,"id":"a8ebea83-36e8-4355-b23f-c3b4a33b8602","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":47,"jupyter":{"outputs_hidden":false,"source_hidden":true},"lastExecutedAt":1709499694143,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n    \"\"\"\n    Convert Monthly data into Daily data and impute with monthly mean prices\n    \"\"\"\n    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n\n    # Generate a complete range of daily dates for the year for imputation\n    start_date = df['Date'].min() # represents the starting point of your data\n    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n\n    # Merge the full date range with the monthly averages to fill in all days\n    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n    return df_daily"},"outputs":[],"source":["def monthly_mean_to_daily(df_monthly: pd.core.frame.DataFrame ) -> pd.core.frame.DataFrame:\n","    \"\"\"\n","    Convert Monthly data into Daily data and impute with monthly mean prices\n","    \"\"\"\n","    df_monthly['Date'] = pd.to_datetime(df_monthly[['Year', 'Month']].assign(DAY=1))\n","    df = df_monthly.explode('Date') # The explode() method converts each element of the specified column(s) into a row.\n","\n","    # Generate a complete range of daily dates for the year for imputation\n","    start_date = df['Date'].min() # represents the starting point of your data\n","    end_date = df['Date'].max() + pd.offsets.MonthEnd(1)  # finds the maximum (or latest) date and include the last month fully\n","    full_date_range = pd.date_range(start=start_date, end=end_date, freq='D') # generates a fixed-frequency DatetimeIndex\n","\n","    # Merge the full date range with the monthly averages to fill in all days\n","    df_full_date_range = pd.DataFrame(full_date_range, columns=['Date'])\n","    df = pd.merge(df_full_date_range, df_monthly, on='Date', how='left')\n","    df_daily = df.ffill(axis=0) # to fill the missing value based on last valid observation following index sequence\n","    return df_daily"]},{"cell_type":"code","execution_count":16,"id":"ca1221ea-d302-4c06-a97a-91017aa8eeea","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":48,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1709499694192,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly electrcity data\nelec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\nelec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\nelec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n\nprint(elec_df.info())\nprint(elec_df.groupby(['Year']).count())\nprint(elec_df.isna().sum().sort_values()) # checking missing values","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 156 entries, 0 to 155\n","Data columns (total 4 columns):\n"," #   Column       Non-Null Count  Dtype         \n","---  ------       --------------  -----         \n"," 0   Year         156 non-null    int64         \n"," 1   Month        156 non-null    int64         \n"," 2   Electricity  156 non-null    float64       \n"," 3   Time         156 non-null    datetime64[ns]\n","dtypes: datetime64[ns](1), float64(1), int64(2)\n","memory usage: 5.0 KB\n","None\n","      Month  Electricity  Time\n","Year                          \n","2011     12           12    12\n","2012     12           12    12\n","2013     12           12    12\n","2014     12           12    12\n","2015     12           12    12\n","2016     12           12    12\n","2017     12           12    12\n","2018     12           12    12\n","2019     12           12    12\n","2020     12           12    12\n","2021     12           12    12\n","2022     12           12    12\n","2023     12           12    12\n","Year           0\n","Month          0\n","Electricity    0\n","Time           0\n","dtype: int64\n"]}],"source":["## Import monthly electrcity data\n","elec_df = pd.read_csv('ELECTRICITY.csv').iloc[:,1:]\n","elec_df['Time'] = pd.to_datetime(elec_df['Year'].astype(str) + elec_df['Month'].astype(str), format='%Y%m')\n","elec_df = elec_df[elec_df['Year'].between(2011,2023)].reset_index().drop('index',axis=1)\n","\n","print(elec_df.info())\n","print(elec_df.groupby(['Year']).count())\n","print(elec_df.isna().sum().sort_values()) # checking missing values"]},{"cell_type":"code","execution_count":17,"id":"b71f7113-0cfa-4a46-8130-9b07e18d20a9","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":235,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1709499694427,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import monthly TTF_GAS data\napiKey = '29219060bc68b2802af8584e0f328b52'\nfred = Fred(api_key=apiKey)\n\n# Get Natural Gas prices in Europe per month\nTTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n                       columns=['PNGASEUUSDM']).reset_index() \nTTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\nTTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\nTTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\nTTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\nTTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n\nprint(TTF_gas_df.info())\nprint(TTF_gas_df.groupby(['Year']).count())\nprint(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n\n\n","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 156 entries, 312 to 467\n","Data columns (total 4 columns):\n"," #   Column       Non-Null Count  Dtype         \n","---  ------       --------------  -----         \n"," 0   Time         156 non-null    datetime64[ns]\n"," 1   PNGASEUUSDM  156 non-null    float64       \n"," 2   Year         156 non-null    int64         \n"," 3   Month        156 non-null    int64         \n","dtypes: datetime64[ns](1), float64(1), int64(2)\n","memory usage: 6.1 KB\n","None\n","      Time  PNGASEUUSDM  Month\n","Year                          \n","2011    12           12     12\n","2012    12           12     12\n","2013    12           12     12\n","2014    12           12     12\n","2015    12           12     12\n","2016    12           12     12\n","2017    12           12     12\n","2018    12           12     12\n","2019    12           12     12\n","2020    12           12     12\n","2021    12           12     12\n","2022    12           12     12\n","2023    12           12     12\n","Time           0\n","PNGASEUUSDM    0\n","Year           0\n","Month          0\n","dtype: int64\n"]}],"source":["## Import monthly TTF_GAS data\n","apiKey = '29219060bc68b2802af8584e0f328b52'\n","fred = Fred(api_key=apiKey)\n","\n","# Get Natural Gas prices in Europe per month\n","TTF_gas_df = pd.DataFrame(fred.get_series('PNGASEUUSDM'), \n","                       columns=['PNGASEUUSDM']).reset_index() \n","TTF_gas_df['index'] = pd.to_datetime(TTF_gas_df['index'], format='%Y-%m-%d')\n","TTF_gas_df['Year'] = TTF_gas_df['index'].dt.year\n","TTF_gas_df['Month'] = TTF_gas_df['index'].dt.month\n","TTF_gas_df = TTF_gas_df[TTF_gas_df['Year'].between(2011,2023)]\n","TTF_gas_df.rename(columns = {'index':'Time'}, inplace = True)\n","\n","print(TTF_gas_df.info())\n","print(TTF_gas_df.groupby(['Year']).count())\n","print(TTF_gas_df.isna().sum().sort_values()) # Check missing values\n","\n","\n"]},{"cell_type":"code","execution_count":18,"id":"af06d94f-1218-4363-a83d-f5ac1783022a","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":75,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1709499694503,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Import price evaluatioin data\nprice_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\nprice_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\nprice_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\nprice_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\nprice_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n\nprice_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n\n# Drop unnecessary columns\nprice_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n\nprint(price_evo_df.info())\nprint(price_evo_df.groupby(['Year']).count())\nprint(price_evo_df.isna().sum().sort_values()) # Check missing values\n\n","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 20570 entries, 0 to 20569\n","Data columns (total 6 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   Time               20570 non-null  datetime64[ns]\n"," 1   Group Description  20570 non-null  object        \n"," 2   Key RM code        20570 non-null  object        \n"," 3   PRICE (EUR/kg)     20570 non-null  float64       \n"," 4   Year               20570 non-null  int64         \n"," 5   Month              20570 non-null  int64         \n","dtypes: datetime64[ns](1), float64(1), int64(2), object(2)\n","memory usage: 964.3+ KB\n","None\n","      Time  Group Description  Key RM code  PRICE (EUR/kg)  Month\n","Year                                                             \n","2012   604                604          604             604    604\n","2013   634                634          634             634    634\n","2014   803                803          803             803    803\n","2015   860                860          860             860    860\n","2016  1057               1057         1057            1057   1057\n","2017  1339               1339         1339            1339   1339\n","2018  1589               1589         1589            1589   1589\n","2019  2151               2151         2151            2151   2151\n","2020  2403               2403         2403            2403   2403\n","2021  2954               2954         2954            2954   2954\n","2022  3215               3215         3215            3215   3215\n","2023  2961               2961         2961            2961   2961\n","Time                 0\n","Group Description    0\n","Key RM code          0\n","PRICE (EUR/kg)       0\n","Year                 0\n","Month                0\n","dtype: int64\n"]}],"source":["## Import price evaluatioin data\n","price_evo_df = pd.read_csv('Dataset_Predicting_Price_Evolutions.csv').iloc[:,1:]\n","price_evo_df['POSTING DATE'] = pd.to_datetime(price_evo_df['POSTING DATE'], format='%Y-%m-%d')\n","price_evo_df['Year'] = price_evo_df['POSTING DATE'].dt.year\n","price_evo_df['Month'] = price_evo_df['POSTING DATE'].dt.month\n","# price_evo_df = price_evo_df.sort_values(['Year','Month'],ascending=True)\n","price_evo_df = price_evo_df[price_evo_df['Year'].between(2012,2023)].reset_index().drop(['index'], axis=1)\n","\n","price_evo_df.rename(columns = {'POSTING DATE':'Time'}, inplace = True)\n","\n","# Drop unnecessary columns\n","price_evo_df = price_evo_df.drop(['SITE', 'SUPPLIER NUMBER', 'PURCHASE NUMBER', 'WEIGHT (kg)'], axis=1)\n","\n","print(price_evo_df.info())\n","print(price_evo_df.groupby(['Year']).count())\n","print(price_evo_df.isna().sum().sort_values()) # Check missing values\n","\n"]},{"cell_type":"code","execution_count":19,"id":"dcfaf48e-a15e-463f-9616-1a05c2f13f3e","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":53,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1709499694556,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create rows and encoding Alkalis_RM02_0001, \n## To calculate the monthly average prices of Alkalis\nAlkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\nAlkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n\n# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\nAlkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n# combine dummy variables with Alkalis_df\nAlkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\n\n## Calculate the average raw material price\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\nResetting the index of the resulting series is necessary to ensure that the indices align properly when merging the series back into the original dataframe.\n\nWhen you perform a groupby operation in pandas, the resulting object is a new DataFrame or Series with a hierarchical index (MultiIndex) if you group by multiple columns. In your case, when you group by ['Year', 'Month'] and calculate the mean, the resulting Series has a MultiIndex consisting of 'Year' and 'Month'.\n\nMerging this Series directly with the original dataframe without resetting the index could lead to issues because the indices won't align properly, and you may end up with NaN values or incorrect mappings.\n\nResetting the index of the resulting series converts the indices into regular integer indices, making it easier to merge with the original dataframe based on the common columns ('Year' and 'Month'). This ensures that the average prices are correctly aligned with the corresponding rows in the original dataframe.\n\"\"\"\naverage_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n                                    .mean()\\\n                                    .reset_index()\n\n# Merge the average monthly price with the original dataframe\nAlkalis_df_dummies = pd.merge(Alkalis_df_dummies, average_price, on=['Year','Month'], suffixes=('', '_avg'))\n\n# Rename the new column to 'Average_price'\nAlkalis_df_dummies.rename(columns={'PRICE (EUR/kg)_avg': 'Average_price'}, inplace=True)\nAlkalis_df_dummies = Alkalis_df_dummies.drop('PRICE (EUR/kg)', axis=1)\n\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.sort_values('Time'))\nprint(Alkalis_df_dummies.isna().sum().sort_values())\n","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 6007 entries, 0 to 6006\n","Data columns (total 6 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   Time               6007 non-null   datetime64[ns]\n"," 1   Group Description  6007 non-null   object        \n"," 2   Year               6007 non-null   int64         \n"," 3   Month              6007 non-null   int64         \n"," 4   RM02/0002          6007 non-null   uint8         \n"," 5   Average_price      6007 non-null   float64       \n","dtypes: datetime64[ns](1), float64(1), int64(2), object(1), uint8(1)\n","memory usage: 287.4+ KB\n","None\n","           Time Group Description  Year  Month  RM02/0002  Average_price\n","0    2012-01-31           Alkalis  2012      1          0       0.214250\n","1    2012-01-31           Alkalis  2012      1          0       0.214250\n","2    2012-01-31           Alkalis  2012      1          0       0.214250\n","3    2012-01-31           Alkalis  2012      1          0       0.214250\n","4    2012-01-31           Alkalis  2012      1          0       0.214250\n","...         ...               ...   ...    ...        ...            ...\n","5931 2023-10-31           Alkalis  2023     10          0       0.353338\n","5932 2023-10-31           Alkalis  2023     10          0       0.353338\n","5933 2023-10-31           Alkalis  2023     10          0       0.353338\n","5927 2023-10-31           Alkalis  2023     10          0       0.353338\n","5920 2023-10-31           Alkalis  2023     10          1       0.353338\n","\n","[6007 rows x 6 columns]\n","Time                 0\n","Group Description    0\n","Year                 0\n","Month                0\n","RM02/0002            0\n","Average_price        0\n","dtype: int64\n"]}],"source":["## Create rows and encoding Alkalis_RM02_0001, \n","## To calculate the monthly average prices of Alkalis\n","Alkalis_df = price_evo_df[price_evo_df['Group Description']==\"Alkalis\"].sort_values(['Year','Month'],ascending=True)\n","Alkalis_df = Alkalis_df.reset_index().drop('index',axis=1)\n","\n","# encoding Alkalis_RM02_0001, Alkalis_RM02_0002 with n-1 dummy variables\n","Alkalis_df_dummies = pd.get_dummies(Alkalis_df['Key RM code'], drop_first=True)\n","# combine dummy variables with Alkalis_df\n","Alkalis_df_dummies = pd.concat([Alkalis_df, Alkalis_df_dummies], axis=1)\n","Alkalis_df_dummies = Alkalis_df_dummies.drop('Key RM code', axis=1)\n","\n","## Calculate the average raw material price\n","\"\"\"\n","average_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n","                                    .mean()\\\n","                                    .reset_index()\n","Resetting the index of the resulting series is necessary to ensure that the indices align properly when merging the series back into the original dataframe.\n","\n","When you perform a groupby operation in pandas, the resulting object is a new DataFrame or Series with a hierarchical index (MultiIndex) if you group by multiple columns. In your case, when you group by ['Year', 'Month'] and calculate the mean, the resulting Series has a MultiIndex consisting of 'Year' and 'Month'.\n","\n","Merging this Series directly with the original dataframe without resetting the index could lead to issues because the indices won't align properly, and you may end up with NaN values or incorrect mappings.\n","\n","Resetting the index of the resulting series converts the indices into regular integer indices, making it easier to merge with the original dataframe based on the common columns ('Year' and 'Month'). This ensures that the average prices are correctly aligned with the corresponding rows in the original dataframe.\n","\"\"\"\n","average_price = Alkalis_df_dummies.groupby(['Year','Month'])['PRICE (EUR/kg)']\\\n","                                    .mean()\\\n","                                    .reset_index()\n","\n","# Merge the average monthly price with the original dataframe\n","Alkalis_df_dummies = pd.merge(Alkalis_df_dummies, average_price, on=['Year','Month'], suffixes=('', '_avg'))\n","\n","# Rename the new column to 'Average_price'\n","Alkalis_df_dummies.rename(columns={'PRICE (EUR/kg)_avg': 'Average_price'}, inplace=True)\n","Alkalis_df_dummies = Alkalis_df_dummies.drop('PRICE (EUR/kg)', axis=1)\n","\n","print(Alkalis_df_dummies.info())\n","print(Alkalis_df_dummies.sort_values('Time'))\n","print(Alkalis_df_dummies.isna().sum().sort_values())\n"]},{"cell_type":"code","execution_count":20,"id":"af348660-2ae0-4781-bd13-8649ecd482d1","metadata":{"executionCancelledAt":null,"executionTime":319,"lastExecutedAt":1709499694875,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Create 12*N features, external factor prices from one-month before to 12-month before\n## Combine features with target variables\n# To prepare feature datasets\nmerged_df = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\nfeature_df = merged_df.copy()\nfeature_df['Time_label'] = feature_df['Time'].dt.strftime('%Y-%m')\nfeature_df = feature_df.drop(['Year','Month', 'Time'], axis=1) # to prevent duplicate columns when merging\n\n# create time labels\nlabel_dfs=[]    # To store labels\n                # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\n    \nfor i in range(1,13): # 13 is not included\n    label = Alkalis_df_dummies[['Time']]\n    label.rename(columns = {'Time':f'Time_label{i}'}, inplace = True)\n    label = (label[f'Time_label{i}'] - pd.DateOffset(months=i)).dt.strftime('%Y-%m')\n    label_dfs.append(label)\n\nresult = pd.concat(label_dfs, axis=1)\n\n# To merge with features\nfor i in range(1,13): # 13 is not included\n    result = result.merge(feature_df, how='left',\\\n                          left_on=[f'Time_label{i}'],\\\n                          right_on=['Time_label'])\n    result.rename(columns = {'Electricity':f'Electricity_{i}',\n                              'PNGASEUUSDM':f'PNGASEUUSDM_{i}'\n                             }, inplace = True)\n    result = result.drop(['Time_label',f'Time_label{i}'], axis=1)\n    \nAlkalis_df_dummies = pd.concat([Alkalis_df_dummies,result],axis=1)\nprint(Alkalis_df_dummies.info())\nprint(Alkalis_df_dummies.head(20))\n\n","outputsMetadata":{"0":{"height":431,"type":"stream"},"1":{"height":217,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 6007 entries, 0 to 6006\n","Data columns (total 30 columns):\n"," #   Column             Non-Null Count  Dtype         \n","---  ------             --------------  -----         \n"," 0   Time               6007 non-null   datetime64[ns]\n"," 1   Group Description  6007 non-null   object        \n"," 2   Year               6007 non-null   int64         \n"," 3   Month              6007 non-null   int64         \n"," 4   RM02/0002          6007 non-null   uint8         \n"," 5   Average_price      6007 non-null   float64       \n"," 6   Electricity_1      6007 non-null   float64       \n"," 7   PNGASEUUSDM_1      6007 non-null   float64       \n"," 8   Electricity_2      6007 non-null   float64       \n"," 9   PNGASEUUSDM_2      6007 non-null   float64       \n"," 10  Electricity_3      6007 non-null   float64       \n"," 11  PNGASEUUSDM_3      6007 non-null   float64       \n"," 12  Electricity_4      6007 non-null   float64       \n"," 13  PNGASEUUSDM_4      6007 non-null   float64       \n"," 14  Electricity_5      6007 non-null   float64       \n"," 15  PNGASEUUSDM_5      6007 non-null   float64       \n"," 16  Electricity_6      6007 non-null   float64       \n"," 17  PNGASEUUSDM_6      6007 non-null   float64       \n"," 18  Electricity_7      6007 non-null   float64       \n"," 19  PNGASEUUSDM_7      6007 non-null   float64       \n"," 20  Electricity_8      6007 non-null   float64       \n"," 21  PNGASEUUSDM_8      6007 non-null   float64       \n"," 22  Electricity_9      6007 non-null   float64       \n"," 23  PNGASEUUSDM_9      6007 non-null   float64       \n"," 24  Electricity_10     6007 non-null   float64       \n"," 25  PNGASEUUSDM_10     6007 non-null   float64       \n"," 26  Electricity_11     6007 non-null   float64       \n"," 27  PNGASEUUSDM_11     6007 non-null   float64       \n"," 28  Electricity_12     6007 non-null   float64       \n"," 29  PNGASEUUSDM_12     6007 non-null   float64       \n","dtypes: datetime64[ns](1), float64(25), int64(2), object(1), uint8(1)\n","memory usage: 1.4+ MB\n","None\n","         Time Group Description  ...  Electricity_12  PNGASEUUSDM_12\n","0  2012-01-31           Alkalis  ...           56.66            9.19\n","1  2012-01-31           Alkalis  ...           56.66            9.19\n","2  2012-01-31           Alkalis  ...           56.66            9.19\n","3  2012-01-31           Alkalis  ...           56.66            9.19\n","4  2012-01-31           Alkalis  ...           56.66            9.19\n","5  2012-01-31           Alkalis  ...           56.66            9.19\n","6  2012-01-31           Alkalis  ...           56.66            9.19\n","7  2012-01-31           Alkalis  ...           56.66            9.19\n","8  2012-02-29           Alkalis  ...           57.72            9.14\n","9  2012-02-29           Alkalis  ...           57.72            9.14\n","10 2012-02-29           Alkalis  ...           57.72            9.14\n","11 2012-02-29           Alkalis  ...           57.72            9.14\n","12 2012-02-29           Alkalis  ...           57.72            9.14\n","13 2012-02-29           Alkalis  ...           57.72            9.14\n","14 2012-02-29           Alkalis  ...           57.72            9.14\n","15 2012-02-29           Alkalis  ...           57.72            9.14\n","16 2012-02-24           Alkalis  ...           57.72            9.14\n","17 2012-03-31           Alkalis  ...           51.43            9.12\n","18 2012-03-31           Alkalis  ...           51.43            9.12\n","19 2012-03-31           Alkalis  ...           51.43            9.12\n","\n","[20 rows x 30 columns]\n"]}],"source":["## Create 12*N features, external factor prices from one-month before to 12-month before\n","## Combine features with target variables\n","# To prepare feature datasets\n","merged_df = pd.merge(elec_df, TTF_gas_df,how='left', on = (['Year', 'Month', 'Time']))\n","feature_df = merged_df.copy()\n","feature_df['Time_label'] = feature_df['Time'].dt.strftime('%Y-%m')\n","feature_df = feature_df.drop(['Year','Month', 'Time'], axis=1) # to prevent duplicate columns when merging\n","\n","# create time labels\n","label_dfs=[]    # To store labels\n","                # ref: 'https://pandas.pydata.org/docs/user_guide/merging.html'\n","    \n","for i in range(1,13): # 13 is not included\n","    label = Alkalis_df_dummies[['Time']]\n","    label.rename(columns = {'Time':f'Time_label{i}'}, inplace = True)\n","    label = (label[f'Time_label{i}'] - pd.DateOffset(months=i)).dt.strftime('%Y-%m')\n","    label_dfs.append(label)\n","\n","result = pd.concat(label_dfs, axis=1)\n","\n","# To merge with features\n","for i in range(1,13): # 13 is not included\n","    result = result.merge(feature_df, how='left',\\\n","                          left_on=[f'Time_label{i}'],\\\n","                          right_on=['Time_label'])\n","    result.rename(columns = {'Electricity':f'Electricity_{i}',\n","                              'PNGASEUUSDM':f'PNGASEUUSDM_{i}'\n","                             }, inplace = True)\n","    result = result.drop(['Time_label',f'Time_label{i}'], axis=1)\n","    \n","Alkalis_df_dummies = pd.concat([Alkalis_df_dummies,result],axis=1)\n","print(Alkalis_df_dummies.info())\n","print(Alkalis_df_dummies.head(20))\n","\n"]},{"cell_type":"code","execution_count":21,"id":"48e7f43f-d67c-4079-a16e-4cc3f57de35e","metadata":{"collapsed":false,"executionCancelledAt":null,"executionTime":102,"jupyter":{"outputs_hidden":false,"source_hidden":false},"lastExecutedAt":1709499694977,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## train_test_split() - RM02/0001\n## Log transformation\n\n# Observe data distribution\n# Alkalis_df_dummies.drop(['Time', 'Group Description', 'Year','Month'],axis=1).hist()\n# Alkalis_df_dummies['Average_price'].hist()\n\n# Create X, y\nRM02_0001 = Alkalis_df_dummies['RM02/0002'] ==0\nX = Alkalis_df_dummies[RM02_0001].drop(['RM02/0002','Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\ny = Alkalis_df_dummies[RM02_0001]['Average_price'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # 30% of our data as the test set\n\n# Log transformation - data is highly skewed\npow_trans_x = PowerTransformer()\npow_trans_x.fit(X_train)\nX_train_log = pow_trans_x.transform(X_train)\nX_test_log = pow_trans_x.transform(X_test)\n\npow_trans_y = PowerTransformer()\npow_trans_y.fit(y_train.reshape(-1, 1))  # Reshape y_train before fitting\ny_train_log = pow_trans_y.transform(y_train.reshape(-1, 1))  # Reshape y_train during transformation\ny_test_log = pow_trans_y.transform(y_test.reshape(-1, 1))  # Reshape y_test during transformation\n","outputsMetadata":{"0":{"height":237,"type":"stream"}}},"outputs":[],"source":["## train_test_split() - RM02/0001\n","## Log transformation\n","\n","# Observe data distribution\n","# Alkalis_df_dummies.drop(['Time', 'Group Description', 'Year','Month'],axis=1).hist()\n","# Alkalis_df_dummies['Average_price'].hist()\n","\n","# Create X, y\n","RM02_0001 = Alkalis_df_dummies['RM02/0002'] ==0\n","X = Alkalis_df_dummies[RM02_0001].drop(['RM02/0002','Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\n","y = Alkalis_df_dummies[RM02_0001]['Average_price'].values\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y) # 30% of our data as the test set\n","\n","# Log transformation - data is highly skewed\n","pow_trans_x = PowerTransformer()\n","pow_trans_x.fit(X_train)\n","X_train_log = pow_trans_x.transform(X_train)\n","X_test_log = pow_trans_x.transform(X_test)\n","\n","pow_trans_y = PowerTransformer()\n","pow_trans_y.fit(y_train.reshape(-1, 1))  # Reshape y_train before fitting\n","y_train_log = pow_trans_y.transform(y_train.reshape(-1, 1))  # Reshape y_train during transformation\n","y_test_log = pow_trans_y.transform(y_test.reshape(-1, 1))  # Reshape y_test during transformation\n"]},{"cell_type":"code","execution_count":22,"id":"b8215f5e-fb58-41ec-a76f-10a7cc271c58","metadata":{"executionCancelledAt":null,"executionTime":24871,"lastExecutedAt":1709499719850,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Lasso regression - fit and transform train data set\n## Cross validation and Hyperparameter tuning using RandomizedSearchCV\n\n# Define the parameter grid\nparam_grid = {'alpha': np.linspace(0.000001, 1, 3000)}\n\n# Create a Lasso regression model\nlasso = Lasso()\n\n# Create RandomizedSearchCV object\nrandom_search = RandomizedSearchCV(estimator=lasso, \n                                   # param_grid defines the grid of hyperparameters to search over.\n                                   param_distributions=param_grid, \n                                   # n_iter determines the number samples\n                                   n_iter=300, \n                                   # cv parameter sets the number of folds for cross-validation.\n                                   cv=5, \n                                   random_state=42)\n\n# Fit the data to perform a grid search\nrandom_search.fit(X_train_log, y_train_log)\n\n# Best alpha parameter\nprint(\"Best alpha parameter:\", round(random_search.best_params_['alpha'],6))\n\n\n# Best R-squared score\nprint(\"Best R-squared score:\", round(random_search.best_score_, 6))\n\n# Coefficients of the best Lasso model\nfeature_names = Alkalis_df_dummies.drop(['RM02/0002','Time', 'Group Description', 'Year', 'Month', 'Average_price'], axis=1).columns\nassert random_search.n_features_in_ == len(feature_names)\n\nprint(\"Coefficients of the selected features in the best Lasso model:\")\nfor feature, coefficient in zip(feature_names, random_search.best_estimator_.coef_):\n    print(f\"{feature}: {round(coefficient,6)}\")","outputsMetadata":{"0":{"height":431,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Best alpha parameter: 1e-06\n","Best R-squared score: 0.835712\n","Coefficients of the selected features in the best Lasso model:\n","Electricity_1: 0.440158\n","PNGASEUUSDM_1: -0.157847\n","Electricity_2: 0.082205\n","PNGASEUUSDM_2: 0.114549\n","Electricity_3: -0.01989\n","PNGASEUUSDM_3: -0.186472\n","Electricity_4: 0.078796\n","PNGASEUUSDM_4: 0.239329\n","Electricity_5: 0.075916\n","PNGASEUUSDM_5: -0.10317\n","Electricity_6: 0.038709\n","PNGASEUUSDM_6: 0.069678\n","Electricity_7: 0.163749\n","PNGASEUUSDM_7: 0.130091\n","Electricity_8: 0.00267\n","PNGASEUUSDM_8: 0.076653\n","Electricity_9: -0.038739\n","PNGASEUUSDM_9: -0.24087\n","Electricity_10: 0.161055\n","PNGASEUUSDM_10: 0.075369\n","Electricity_11: 0.097241\n","PNGASEUUSDM_11: 0.014895\n","Electricity_12: -0.037417\n","PNGASEUUSDM_12: -0.0693\n"]}],"source":["## Lasso regression - fit and transform train data set\n","## Cross validation and Hyperparameter tuning using RandomizedSearchCV\n","\n","# Define the parameter grid\n","param_grid = {'alpha': np.linspace(0.000001, 1, 3000)}\n","\n","# Create a Lasso regression model\n","lasso = Lasso()\n","\n","# Create RandomizedSearchCV object\n","random_search = RandomizedSearchCV(estimator=lasso, \n","                                   # param_grid defines the grid of hyperparameters to search over.\n","                                   param_distributions=param_grid, \n","                                   # n_iter determines the number samples\n","                                   n_iter=300, \n","                                   # cv parameter sets the number of folds for cross-validation.\n","                                   cv=5, \n","                                   random_state=42)\n","\n","# Fit the data to perform a grid search\n","random_search.fit(X_train_log, y_train_log)\n","\n","# Best alpha parameter\n","print(\"Best alpha parameter:\", round(random_search.best_params_['alpha'],6))\n","\n","\n","# Best R-squared score\n","print(\"Best R-squared score:\", round(random_search.best_score_, 6))\n","\n","# Coefficients of the best Lasso model\n","feature_names = Alkalis_df_dummies.drop(['RM02/0002','Time', 'Group Description', 'Year', 'Month', 'Average_price'], axis=1).columns\n","assert random_search.n_features_in_ == len(feature_names)\n","\n","print(\"Coefficients of the selected features in the best Lasso model:\")\n","for feature, coefficient in zip(feature_names, random_search.best_estimator_.coef_):\n","    print(f\"{feature}: {round(coefficient,6)}\")"]},{"cell_type":"code","execution_count":23,"id":"49a8e9d1-f461-4266-981f-9edd99e8fd77","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1709499838202,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"## Lasso regression - transform test data set\n# Get the best Lasso model from RandomizedSearchCV\nbest_lasso_model = random_search.best_estimator_\n\n# Fit the best Lasso model to the test data\nbest_lasso_model.fit(X_test_log, y_test_log)\n\n# Predict on the test data\ny_pred_test = best_lasso_model.predict(X_test_log)\n\n# Evaluate the model performance on the test data\ntest_score = best_lasso_model.score(X_test_log, y_test_log)\nprint(\"Test Set R-squared score:\", test_score)"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Set R-squared score: 0.836318838722741\n"]}],"source":["## Lasso regression - transform test data set\n","# Get the best Lasso model from RandomizedSearchCV\n","best_lasso_model = random_search.best_estimator_\n","\n","# Fit the best Lasso model to the test data\n","best_lasso_model.fit(X_test_log, y_test_log)\n","\n","# Predict on the test data\n","y_pred_test = best_lasso_model.predict(X_test_log)\n","\n","# Evaluate the model performance on the test data\n","test_score = best_lasso_model.score(X_test_log, y_test_log)\n","print(\"Test Set R-squared score:\", test_score)"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
